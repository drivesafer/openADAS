<!doctype html>
<html lang="vi">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
  <title>Traffic Sign Detect (ONNX)</title>
  <style>
    :root { color-scheme: dark; }
    body { margin:0; font-family: system-ui,-apple-system,Segoe UI,Roboto,Arial; background:#0b0f14; color:#e8eef6; }
    header { padding:12px 14px; display:flex; gap:10px; align-items:center; justify-content:space-between; flex-wrap:wrap; }
    .btn { appearance:none; border:1px solid #2b3542; background:#141b24; color:#e8eef6; padding:10px 12px; border-radius:12px; font-weight:700; }
    .btn:active { transform: translateY(1px); }
    .row { display:flex; gap:10px; align-items:center; flex-wrap:wrap; }
    label { font-size:13px; opacity:.9; display:flex; gap:8px; align-items:center; }
    input[type="range"]{ width:140px; }
    main { padding:0 12px 14px; }
    .stage { position:relative; width:100%; max-width:980px; margin:0 auto; border:1px solid #253041; border-radius:16px; overflow:hidden; background:#000; }
    video, canvas { position:absolute; inset:0; width:100%; height:100%; }
    .stage::before { content:""; display:block; padding-top:56.25%; }
    .hud { position:absolute; left:10px; bottom:10px; background:rgba(0,0,0,.45); border:1px solid rgba(255,255,255,.12);
           border-radius:12px; padding:8px 10px; font-size:13px; backdrop-filter: blur(6px); }
    .muted { opacity:.8; }
    code { opacity:.9; }
  </style>
</head>
<body>
  <header>
    <div class="row">
      <button id="btnStart" class="btn">Start</button>
      <button id="btnStop" class="btn" disabled>Stop</button>
      <button id="btnFlip" class="btn" disabled>Flip</button>
    </div>

    <div class="row">
      <label>Conf
        <input id="conf" type="range" min="0" max="1" step="0.01" value="0.35" />
        <span id="confVal">0.35</span>
      </label>
      <label>NMS
        <input id="nms" type="range" min="0" max="1" step="0.01" value="0.45" />
        <span id="nmsVal">0.45</span>
      </label>
      <label>Skip
        <input id="skip" type="range" min="0" max="5" step="1" value="2" />
        <span id="skipVal">2</span>
      </label>
    </div>
  </header>

  <main>
    <div class="stage">
      <video id="video" playsinline muted></video>
      <canvas id="overlay"></canvas>
      <div class="hud">
        <div><b>Status:</b> <span id="status">idle</span></div>
        <div class="muted">Provider: <span id="prov">-</span></div>
        <div class="muted">FPS: <span id="fps">-</span> · Boxes: <span id="boxes">-</span></div>
      </div>
    </div>

    <p class="muted" style="max-width:980px;margin:10px auto 0;padding:0 2px;">
      Chạy bằng server tĩnh (không dùng file://). Ví dụ: <code>python -m http.server</code> rồi mở <code>http://localhost:8000</code>.
    </p>
  </main>

  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script>
    // ===== CONFIG =====
    const MODEL_URL = "./model.onnx";        // đổi nếu bạn dùng tên khác
    const INPUT_SIZE = 320;                  // ép 320 (đã tối ưu)
    const TARGET_FPS = 60;                   // loop UI; inference sẽ bị skip
    const MAX_DETECTIONS = 40;

    // ===== UI =====
    const $ = (id) => document.getElementById(id);
    const video = $("video");
    const canvas = $("overlay");
    const ctx = canvas.getContext("2d");
    const statusEl = $("status");
    const provEl = $("prov");
    const fpsEl = $("fps");
    const boxesEl = $("boxes");

    const btnStart = $("btnStart");
    const btnStop  = $("btnStop");
    const btnFlip  = $("btnFlip");

    const confSlider = $("conf"), nmsSlider = $("nms"), skipSlider = $("skip");
    const confVal = $("confVal"), nmsVal = $("nmsVal"), skipVal = $("skipVal");
    confSlider.oninput = () => confVal.textContent = (+confSlider.value).toFixed(2);
    nmsSlider.oninput  = () => nmsVal.textContent  = (+nmsSlider.value).toFixed(2);
    skipSlider.oninput = () => skipVal.textContent = (+skipSlider.value).toFixed(0);

    // ===== STATE =====
    let stream = null;
    let session = null;
    let inputName = null;
    let facingMode = "environment";
    let running = false;

    // Preprocess canvas (reuse)
    const workCanvas = document.createElement("canvas");
    const workCtx = workCanvas.getContext("2d", { willReadFrequently: true });

    // Reuse input buffer/tensor (critical for GC)
    let inputBuffer = null;
    let inputTensor = null;

    // Keep last detections for drawing when skipping inference
    let lastBoxes = [];

    // FPS smoothing
    let lastLoopTs = 0;
    let fps = 0;

    function setStatus(s) { statusEl.textContent = s; }

    function resizeOverlay() {
      const rect = video.getBoundingClientRect();
      const dpr = window.devicePixelRatio || 1;
      canvas.width  = Math.round(rect.width * dpr);
      canvas.height = Math.round(rect.height * dpr);
      ctx.setTransform(dpr, 0, 0, dpr, 0, 0); // draw in CSS pixels
    }

    function clamp(v, lo, hi) { return Math.max(lo, Math.min(hi, v)); }

    function iou(a, b) {
      const x1 = Math.max(a.x1, b.x1), y1 = Math.max(a.y1, b.y1);
      const x2 = Math.min(a.x2, b.x2), y2 = Math.min(a.y2, b.y2);
      const w = Math.max(0, x2 - x1), h = Math.max(0, y2 - y1);
      const inter = w * h;
      const areaA = Math.max(0, a.x2 - a.x1) * Math.max(0, a.y2 - a.y1);
      const areaB = Math.max(0, b.x2 - b.x1) * Math.max(0, b.y2 - b.y1);
      return inter / (areaA + areaB - inter + 1e-9);
    }

    function nms(boxes, iouThr) {
      boxes.sort((p, q) => q.score - p.score);
      const keep = [];
      for (const b of boxes) {
        let ok = true;
        for (const k of keep) {
          if (iou(b, k) > iouThr) { ok = false; break; }
        }
        if (ok) keep.push(b);
        if (keep.length >= MAX_DETECTIONS) break;
      }
      return keep;
    }

    function ensureInputReuse() {
      const size = 1 * 3 * INPUT_SIZE * INPUT_SIZE;
      if (!inputBuffer || inputBuffer.length !== size) {
        inputBuffer = new Float32Array(size);
        inputTensor = new ort.Tensor("float32", inputBuffer, [1, 3, INPUT_SIZE, INPUT_SIZE]);
      }
    }

    // Letterbox to INPUT_SIZE and write into inputBuffer (NCHW float32)
    function letterboxToInput(videoEl) {
      const dstW = INPUT_SIZE, dstH = INPUT_SIZE;
      workCanvas.width = dstW;
      workCanvas.height = dstH;

      const srcW = videoEl.videoWidth;
      const srcH = videoEl.videoHeight;

      const r = Math.min(dstW / srcW, dstH / srcH);
      const newW = Math.round(srcW * r);
      const newH = Math.round(srcH * r);
      const padX = Math.floor((dstW - newW) / 2);
      const padY = Math.floor((dstH - newH) / 2);

      workCtx.fillStyle = "black";
      workCtx.fillRect(0, 0, dstW, dstH);
      workCtx.drawImage(videoEl, 0, 0, srcW, srcH, padX, padY, newW, newH);

      const img = workCtx.getImageData(0, 0, dstW, dstH).data;
      const hw = dstH * dstW;

      // Fill inputBuffer in-place
      for (let i = 0; i < hw; i++) {
        const r8 = img[i * 4 + 0];
        const g8 = img[i * 4 + 1];
        const b8 = img[i * 4 + 2];
        inputBuffer[i] = r8 / 255;
        inputBuffer[i + hw] = g8 / 255;
        inputBuffer[i + 2 * hw] = b8 / 255;
      }

      return { scale: r, padX, padY, dstW, dstH };
    }

    // Parse YOLOv8-ish output: supports [1,C,N] or [1,N,C]
    function parseYoloOutput(outTensor, confThr, meta) {
      const data = outTensor.data;
      const dims = outTensor.dims;

      if (!dims || dims.length < 3) return [];

      const d1 = dims[dims.length - 2];
      const d2 = dims[dims.length - 1];

      let N, C, layout;
      if (d1 <= d2) { C = d1; N = d2; layout = "CN"; }
      else { N = d1; C = d2; layout = "NC"; }

      const numClasses = Math.max(0, C - 4);
      const srcW = video.videoWidth, srcH = video.videoHeight;
      const { scale, padX, padY } = meta;

      const boxes = [];
      for (let i = 0; i < N; i++) {
        let x, y, w, h;
        if (layout === "CN") {
          x = data[0 * N + i];
          y = data[1 * N + i];
          w = data[2 * N + i];
          h = data[3 * N + i];
        } else {
          const base = i * C;
          x = data[base + 0];
          y = data[base + 1];
          w = data[base + 2];
          h = data[base + 3];
        }

        let score = 0;
        if (numClasses > 0) {
          if (layout === "CN") {
            for (let c = 4; c < C; c++) score = Math.max(score, data[c * N + i]);
          } else {
            const base = i * C;
            for (let c = 4; c < C; c++) score = Math.max(score, data[base + c]);
          }
        } else score = 1;

        if (score < confThr) continue;

        let x1 = x - w / 2, y1 = y - h / 2, x2 = x + w / 2, y2 = y + h / 2;

        // undo letterbox
        x1 = (x1 - padX) / scale; y1 = (y1 - padY) / scale;
        x2 = (x2 - padX) / scale; y2 = (y2 - padY) / scale;

        x1 = clamp(x1, 0, srcW); y1 = clamp(y1, 0, srcH);
        x2 = clamp(x2, 0, srcW); y2 = clamp(y2, 0, srcH);

        if ((x2 - x1) < 4 || (y2 - y1) < 4) continue;
        boxes.push({ x1, y1, x2, y2, score });
      }
      return boxes;
    }

    function draw(boxes) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      const vw = video.videoWidth, vh = video.videoHeight;
      if (!vw || !vh) return;

      const rect = video.getBoundingClientRect();
      const scaleX = rect.width / vw;
      const scaleY = rect.height / vh;

      ctx.lineWidth = 2;
      ctx.font = "13px system-ui,-apple-system,Segoe UI,Roboto,Arial";
      ctx.textBaseline = "top";

      for (const b of boxes) {
        const x = b.x1 * scaleX;
        const y = b.y1 * scaleY;
        const w = (b.x2 - b.x1) * scaleX;
        const h = (b.y2 - b.y1) * scaleY;

        ctx.strokeStyle = "rgba(0,255,180,0.95)";
        ctx.strokeRect(x, y, w, h);

        const label = (b.score * 100).toFixed(1) + "%";
        const pad = 4;
        const tw = ctx.measureText(label).width;
        ctx.fillStyle = "rgba(0,0,0,0.55)";
        ctx.fillRect(x, y, tw + pad * 2, 18);
        ctx.fillStyle = "rgba(0,255,180,0.95)";
        ctx.fillText(label, x + pad, y + 2);
      }
    }

    async function loadModel() {
      setStatus("loading model…");

      // Make ORT load WASM binaries from CDN (important)
      ort.env.wasm.wasmPaths = "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/";
      ort.env.wasm.numThreads = Math.min(4, navigator.hardwareConcurrency || 4);
      ort.env.wasm.simd = true;

      // Prefer GPU if available, fallback to wasm
      const providers = ["webgpu", "webgl", "wasm"];

      session = await ort.InferenceSession.create(MODEL_URL, {
        executionProviders: providers
      });

      inputName = session.inputNames[0];
      provEl.textContent = (session.executionProvider || "webgpu/webgl/wasm").toString();

      ensureInputReuse();

      // Warm-up (1 inference) to avoid initial lag
      const dummy = new ort.Tensor("float32", inputBuffer, [1, 3, INPUT_SIZE, INPUT_SIZE]);
      await session.run({ [inputName]: dummy });

      setStatus("model ready");
    }

    async function startCamera() {
      setStatus("requesting camera…");
      stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode, width: { ideal: 1280 }, height: { ideal: 720 } },
        audio: false
      });

      video.srcObject = stream;
      await video.play();

      resizeOverlay();
      window.addEventListener("resize", resizeOverlay);

      btnStart.disabled = true;
      btnStop.disabled = false;
      btnFlip.disabled = false;

      setStatus("camera on");
    }

    function stopAll() {
      running = false;
      if (stream) { stream.getTracks().forEach(t => t.stop()); stream = null; }
      video.srcObject = null;
      btnStart.disabled = false;
      btnStop.disabled = true;
      btnFlip.disabled = true;
      lastBoxes = [];
      draw(lastBoxes);
      fpsEl.textContent = "-";
      boxesEl.textContent = "-";
      setStatus("stopped");
    }

    let frameCount = 0;
    let lastInferBoxes = [];
    let lastInferTs = 0;

    async function loop(ts) {
      if (!running) return;

      // UI FPS estimate
      if (lastLoopTs) {
        const inst = 1000 / Math.max(1, ts - lastLoopTs);
        fps = fps ? (fps * 0.85 + inst * 0.15) : inst;
      }
      lastLoopTs = ts;
      fpsEl.textContent = fps ? fps.toFixed(1) : "-";

      const skip = +skipSlider.value;   // infer 1 frame, skip N frames
      const doInfer = (frameCount % (skip + 1) === 0);
      frameCount++;

      if (doInfer && session && video.videoWidth) {
        try {
          const confThr = +confSlider.value;
          const nmsThr  = +nmsSlider.value;

          // preprocess into reused buffer
          const meta = letterboxToInput(video);

          // infer
          const outputs = await session.run({ [inputName]: inputTensor });
          const outName = session.outputNames[0];
          const outTensor = outputs[outName];

          // parse + NMS
          let boxes = parseYoloOutput(outTensor, confThr, meta);
          boxes = nms(boxes, nmsThr);

          lastInferBoxes = boxes;
          lastInferTs = ts;
        } catch (e) {
          console.error(e);
          setStatus("infer error (console)");
        }
      }

      // draw last inferred boxes every frame (smooth perception)
      lastBoxes = lastInferBoxes;
      boxesEl.textContent = lastBoxes.length.toString();
      draw(lastBoxes);

      // throttle loop a bit if you want (optional). We'll just RAF for now.
      requestAnimationFrame(loop);
    }

    btnStart.onclick = async () => {
      try {
        await startCamera();
        if (!session) await loadModel();
        running = true;
        frameCount = 0;
        lastLoopTs = 0;
        lastInferBoxes = [];
        setStatus("running");
        requestAnimationFrame(loop);
      } catch (e) {
        console.error(e);
        setStatus("start error (console)");
      }
    };

    btnStop.onclick = () => stopAll();

    btnFlip.onclick = async () => {
      facingMode = (facingMode === "environment") ? "user" : "environment";
      stopAll();
      await startCamera();
      if (!session) await loadModel();
      running = true;
      frameCount = 0;
      lastLoopTs = 0;
      setStatus("running");
      requestAnimationFrame(loop);
    };

    video.addEventListener("loadedmetadata", resizeOverlay);
  </script>
</body>
</html>
